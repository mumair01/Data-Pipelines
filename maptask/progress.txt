DATE: 5/9/22
- Started implementing the pipeline
- Added ability to download the maptask corpus including the audio.
- Added ability to separate the left and right tracks of the downloaded audio.
- Added ability to use opensmile binaries to extract genome features


DATE: 5/10/22
- Audio download shell script moved to a shell scripts folder to separate scripts.
- Tested method to extract gemap features as expected in the original code.
    - Now uses downloaded opensmile binary from: https://github.com/audeering/opensmile/releases
    - Binary used to extract audio features using opensmile config files by Skantze.

DATE: 5/11/22
- Implementing the get vocabulary method based on the existing implementation.
- There can be another class called MapTaskProcessor that is specific to
    a specific MapTask pipeline.
- There can be a general pipeline class that can manage the Threads etc.
- Notes for when refactoring:
    - Potential classes:
        1. MapTask class --> Responsible for downloading and parsing the corpus.
    - Features to add when refactoring:
        1. Method for obtaining the files in different directories.
        2. Method for obtaining all files and / or sub-dirs in a dir.
        3. General methods for parsing the downloaded data.
        4. Method for collecting files based on common filenames.
        5. Method to extract features given an audio file.
        6. Methods to write to different file formats i.e., hd5, pickle, json etc.
        7. Methods for parsing specific xml files in the original MapTask data.

- IMPORTANT: Added the pipeline up to get average word annotations - choosing not to move
forward because a lot of code is being re-used and it is becoming difficult
to understand.

- Notes about the MapTask corpus
    - f and g stand for "follower" and "giver" for the participants in the dialogue.
    - Left channel is the follower and right is the giver.
    - For the maptask filename:
        1. qx --> x is the quad number.
        2. nc or ec --> nc is no eye contact and ec is eye contact.
        3. xxxxY --> Y is the dialogue number.


DATE: 5/12/22
- Building the refactored pipeline:
    1. Copied the Threads class from GaiBot to multithread but thinking to
        use multithreading package instead.
    2. Creating a separate script that extract audio features using opensmile
        - This can be reused later.

DATE: 5/13/22
- Picking up and continuing the work outlined for 5/12/22.
- Created a refactored and somewhat more modular pipeline.
- Next step is to create POC notebooks to investigate what the features actually mean.
- Determining the exact features produces by opensmile:
    - Downloaded, installed, and added opensmile to default .zshrc path.
    - Investigated the exact configurations and the audio features that were being
    used by opensmile.
        - In roddy's code, he is using eGemapsv01a --> We not use eGemapsv02.
        - To use opensmile, all the Gemaps and eGemaps config files have to be
            copied, along with the shared files.
            See link: https://audeering.github.io/opensmile/get-started.html#default-feature-sets



